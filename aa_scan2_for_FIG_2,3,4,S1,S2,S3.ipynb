{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c65ce7-d377-46d2-a481-6e2f0496ded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e41bfdd-f949-48f3-80a4-0be5899787c7",
   "metadata": {},
   "source": [
    "## 1. Load microarray result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8194b463-4686-42a8-a9be-8a1436ec8723",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf=pd.read_excel(\"Clean_results_2_2019.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce1a4b3-a06c-466a-8fff-9584748e0f69",
   "metadata": {},
   "source": [
    "## 2. Load custom feature scoring and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336bd2e6-de61-42a3-a194-b1ad9994c2e9",
   "metadata": {},
   "source": [
    "### 2.1. Use this for the composition-based feature scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bccc99-366f-4143-885d-39a2c03525fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load feature scoring file\n",
    "df=pd.read_excel(\"aa_properties2_Cpos_19cat.xlsx\") #This one count atom types in each amino acid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71bdb06-3fbc-4378-85d9-0b634c436b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature extraction\n",
    "header=np.asarray(list(df.columns.values))\n",
    "feat=np.delete(header, 0, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a5328f-24f0-4c41-99bd-6ffb27c8441f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count each feature for each peptide in the microarray result\n",
    "#Apply the function in the peptide sequence\n",
    "def aa_count(peptide):\n",
    "#Iterate through each amino acid in peptide sequence\n",
    "    rows=[]\n",
    "    for aa in peptide:\n",
    "        rows.append(df[df.aa==aa])\n",
    "    return pd.concat(rows).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a9f4f9-f09c-41b2-ad5f-28560f9a4f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new df with the function applied to Peptide column from pf\n",
    "transpf=pf['Peptide'].apply(aa_count)\n",
    "transpf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d27f10-bb36-48b2-b334-bed2a0aaea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge transpf table containing amino acid sums to original raw data table pf\n",
    "mergepf = pd.concat([pf, transpf], axis=1, sort=False)\n",
    "mergepf[\"Prot_pep\"] = mergepf[\"Protein\"].map(str) +\"_\"+ mergepf[\"Peptide\"]\n",
    "mergepf[\"Prot_res_pep\"] = mergepf[\"Protein\"].map(str) +\"_\"+ mergepf[\"Residue number\"].map(str)+\"_\"+ mergepf[\"Peptide\"]\n",
    "mergepf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c6d21-8905-45ab-bb2b-f5ce10852826",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[mergepf.filter(feat)]\n",
    "featx=np.reshape(features, (5395, 19), order='A')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77c6dda-383f-4864-913d-3d8a80a8c04b",
   "metadata": {},
   "source": [
    "### 2.2. Use this for the Seq and UniSeq-based feature scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e2ce19-b1f3-44fe-a8ed-2c4e7099fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seq\n",
    "#aadict={'A': 0.78, 'C': 3.14, 'D': 1.25, 'E': 0.94, 'F': 1.07, 'G': 1.13, 'H': 1.03, 'I': 1.26, 'K': 0.85, 'L': 0.91,\n",
    "#        'M': 0.41, 'N': 1.32, 'P': 1.73, 'Q': 0.93, 'R': 1.75, 'S': 1.31, 'T': 1.57, 'Y': 1.31, 'V': 1.11, 'W': 0.98}\n",
    "\n",
    "#UniSeq\n",
    "aadict={'A': 10, 'C': 20, 'D': 30, 'E': 40, 'F': 50, 'G': 60, 'H': 70, 'I': 80, 'K': 90, 'L': 100,\n",
    "        'M': 110, 'N': 120, 'P': 130, 'Q': 140, 'R': 150, 'S': 160, 'T': 170, 'Y': 180, 'V': 190, 'W': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca9f07-a21a-4914-ac7b-a8dd26146845",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace each amino acid with custom scoring in the microarray result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ded2c4-86bf-494b-9df2-623845764242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aa_replace(peptide):\n",
    "    rows=[]\n",
    "    for aa in peptide:\n",
    "        #pepsplit=peptide.split()\n",
    "        rows.append(aadict[aa])\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a486ec0d-323c-4261-bc1c-188d7a1cae3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transpfseq=pf['Peptide'].apply(aa_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b755bb-42de-432e-b20f-e2885f22624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe with the replaced values\n",
    "zfs=[]\n",
    "for idx,row in transpfseq.iteritems():\n",
    "    zf=pd.DataFrame(row)\n",
    "    zfs.append(zf.T)\n",
    "aaconv=pd.concat(zfs)\n",
    "aaconv=aaconv.reset_index()\n",
    "aaconv['Peptide']=pf['Peptide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888fc7a5-e1b0-4903-8a3d-efeee6853c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with original dataframe\n",
    "mergepf = pd.concat([pf,aaconv], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ae761-351f-47f9-a5b3-03387a098fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fourier transform of the replaced values\n",
    "from scipy.fft import fft\n",
    "import matplotlib.pylab as plt\n",
    "fftdf=pd.DataFrame(columns = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"])\n",
    "for idx,row in aaconv.iterrows():\n",
    "    fftlst=fft(np.array(row[list(range(0,15))]))\n",
    "    plt.plot(np.abs(2/15*fftlst[1:15//2])) #need to correct\n",
    "    new_df = pd.DataFrame(data = [np.abs(2/15*fftlst[1:15//2])], columns = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"])\n",
    "    fftdf= pd.concat([fftdf, new_df])\n",
    "\n",
    "fftdf=fftdf.reset_index()\n",
    "newfft= pd.concat([pf,fftdf], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b7634a-7c71-4eeb-a447-f5c12414cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[u\"1\",u\"2\",u\"3\",u\"4\",u\"5\",u\"6\"]\n",
    "featx = np.array(newfft[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a7964-bc76-4a1c-a96c-2351c7135cd8",
   "metadata": {},
   "source": [
    "## 3. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe08e035-160a-45c0-9d76-fae2ca90335d",
   "metadata": {},
   "source": [
    "### 3.1. Use this for the composition-based feature scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e81b04-ab45-4b3a-bdf5-16255e8c0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls=(1,) #hidden layer shape\n",
    "#The optimized grid search hyperparams\n",
    "clf = MLPClassifier(solver='adam', random_state=1, max_iter=10000, hidden_layer_sizes=hls)\n",
    "\n",
    "def pept_class(features):\n",
    "    X = StandardScaler().fit_transform(featx)\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(\n",
    "    #    X, np.array(mergepf[u'Survivin, 1 µg/ml']>0), test_size=0.5, shuffle=True)\n",
    "    #clf.fit(X_train, y_train)\n",
    "    #predicted=clf.predict(X_test)\n",
    "    #return metrics.confusion_matrix(y_test, predicted)\n",
    "    clf.fit(X, np.array(mergepf[u'Survivin, 1 µg/ml']>0))\n",
    "    predicted=clf.predict(X)\n",
    "    return metrics.confusion_matrix(np.array(mergepf[u'Survivin, 1 µg/ml']>0), predicted)\n",
    "confmtxs=[]\n",
    "for i in range(0,100):\n",
    "    confmtx=pept_class(features)\n",
    "    confmtxs.append(confmtx)\n",
    "confmtxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0445c50a-8bc8-4cc4-b8cd-609a021ed426",
   "metadata": {},
   "source": [
    "### 3.2. Use this for the Seq and UniSeq-based feature scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2448a8cf-bf50-4c4b-abe4-9e59564cb0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls=(1,) #hidden layer shape\n",
    "clf = MLPClassifier(solver='adam',random_state=1, max_iter=10000, hidden_layer_sizes=hls)\n",
    "\n",
    "features=[u'1',u'2',u'3',u'4',u'5',u'6']\n",
    "\n",
    "def pept_class(features):\n",
    "    X = np.array(newfft[features])\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, np.array(newfft[u'Survivin, 1 µg/ml']>0), test_size=0.5, shuffle=True)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted=clf.predict(X_train)\n",
    "    return metrics.confusion_matrix(y_train, predicted)\n",
    "confmtxs=[]\n",
    "for i in range(0,100):\n",
    "    confmtx=pept_class(features)\n",
    "    confmtxs.append(confmtx)\n",
    "confmtxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9cd7b9-3947-4b74-8f3f-64284d3098f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat=mean.tolist()+se.tolist()\n",
    "stat.insert(0,hls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2144d4b-90ea-4636-b78d-fa364045de49",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat1=pd.DataFrame(stat)\n",
    "stat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbf3b25-d071-4fcc-b133-c79739bdf0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat1[1]=stat\n",
    "stat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cceb53e-8a1d-42b5-8eef-014e6eb64805",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = stat1.transpose()\n",
    "stats.columns=['Nodes','Mean_Pprec','Mean_Nprec','Mean_Prec','Mean_Nrec','Mean_Acc','Mean_PF1',\n",
    "                                      'Mean_NF1','SE_Pprec','SE_Nprec','SE_Prec','SE_Nrec','SE_Acc','SE_PF1',\n",
    "                                      'SE_NF1']\n",
    "stats.to_excel('output.xlsx', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58d90d7-a3ff-4076-893d-1032689db7b1",
   "metadata": {},
   "source": [
    "## 4. [FIG 2] Different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f63634-5077-476a-812d-d1d06f4d5a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load statistics file\n",
    "pf=pd.read_excel(\"output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474e0817-4b32-4ffc-a63a-74f0f35ddbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    name='Mean Accuracy',\n",
    "    x=pf['Nodes'], y=pf['Mean_Acc'],\n",
    "    error_y=dict(type='data', array=pf['SE_Acc'])\n",
    "    ,mode='markers'\n",
    "    #,mode='markers+lines'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    name='Mean F1 Positive',\n",
    "    x=pf['Nodes'], y=pf['Mean_PF1'],\n",
    "    error_y=dict(type='data', array=pf['SE_PF1'])\n",
    "    ,mode='markers'\n",
    "    #,mode='markers+lines'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    name='Mean F1 Negative',\n",
    "    x=pf['Nodes'], y=pf['Mean_NF1'],\n",
    "    error_y=dict(type='data', array=pf['SE_NF1'])\n",
    "    ,mode='markers'\n",
    "    #,mode='markers+lines'\n",
    "))\n",
    "fig.update_traces(marker_size=8,line=dict(width=2))\n",
    "fig.update_layout(\n",
    "    height=800,width=1000,\n",
    "    #barmode='group',\n",
    "    #title=\"1 Hidden Layer of Varying Number of Nodes\",\n",
    "    xaxis_title=\"Features\",\n",
    "    #yaxis_title=\"Mean Accuracy (%)\",\n",
    "    #legend_title=\"Legend\",\n",
    "    font=dict(\n",
    "        family=\"Open Sans, verdana, arial, sans-serif\",\n",
    "        size=25,\n",
    "        color=\"Rebecca Purple\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5829880-7efb-4e23-9b5e-70ec211d760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"fig_diff_feat_2.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a58018-2df9-4dc4-865b-3b9d016cda70",
   "metadata": {},
   "source": [
    "## 5. [FIG 3] Different number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405106ce-a18a-493c-ac42-0dea5c451751",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load statistics file\n",
    "val=pd.read_excel(\"output_val.xlsx\")\n",
    "noval=pd.read_excel(\"output_noval.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de76b5c5-55f4-4bf8-8944-312d7db90c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(\n",
    "    name='Mean F1 Negative V',\n",
    "    x=val['Nodes'], y=val['Mean_NF1'],\n",
    "    error_y=dict(type='data', array=val['SE_NF1'])\n",
    "    ,mode='markers+lines'\n",
    "    ,line_color='teal'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    name='Mean F1 Negative NV',\n",
    "    x=val['Nodes'], y=noval['Mean_NF1'],\n",
    "    error_y=dict(type='data', array=noval['SE_NF1'])\n",
    "    ,mode='markers+lines'\n",
    "    ,line_color='lightseagreen'\n",
    "    ,fill='tonexty'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    name='Mean F1 Positive V',\n",
    "    x=val['Nodes'], y=val['Mean_PF1'],\n",
    "    error_y=dict(type='data', array=val['SE_PF1'])\n",
    "    ,mode='markers+lines'\n",
    "    ,line_color='deeppink'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    name='Mean F1 Positive NV',\n",
    "    x=val['Nodes'], y=noval['Mean_PF1'],\n",
    "    error_y=dict(type='data', array=noval['SE_PF1'])\n",
    "    ,mode='markers+lines'\n",
    "    ,line_color='hotpink'\n",
    "    ,fill='tonexty'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    name='Mean Accuracy V',\n",
    "    x=val['Nodes'], y=val['Mean_Acc'],\n",
    "    error_y=dict(type='data', array=val['SE_Acc'])\n",
    "    ,mode='markers+lines'\n",
    "    ,line_color='royalblue'\n",
    "))\n",
    "fig.add_trace(go.Scatter(\n",
    "    name='Mean Accuracy NV',\n",
    "    x=val['Nodes'], y=noval['Mean_Acc'],\n",
    "    error_y=dict(type='data', array=noval['SE_Acc'])\n",
    "    ,mode='markers+lines'\n",
    "    ,line_color='dodgerblue'\n",
    "    ,fill='tonexty'\n",
    "))\n",
    "\n",
    "fig.update_traces(marker_size=8,line=dict(width=2))\n",
    "fig.update_layout(\n",
    "    height=800,width=1000,\n",
    "    xaxis_title=\"Number of Nodes\",\n",
    "    yaxis_title=\"Performance Metrics (%)\",\n",
    "    font=dict(\n",
    "        family=\"Open Sans, verdana, arial, sans-serif\",\n",
    "        size=25,\n",
    "        color=\"Rebecca Purple\"\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d8a24-c6f0-4a3c-ab0d-e1b1fded0137",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"fig_valnoval.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd699609-7cb0-4d7b-b136-4629099ae2a1",
   "metadata": {},
   "source": [
    "## 6. [FIG 4] Visualize NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71da3d4-3b9e-4ef6-94e6-846d479b1a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_outputs = np.array([y_train]).T\n",
    "training_set_outputs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0900f5-5af5-4e04-b0d2-23d8493f3f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from math import cos, sin, atan\n",
    "from palettable.matplotlib import Plasma_3\n",
    "from time import localtime, strftime\n",
    "\n",
    "class Neuron():\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def draw(self, neuron_radius, id=-1):\n",
    "        circle = pyplot.Circle((self.x, self.y), radius=neuron_radius, fill=False)\n",
    "        pyplot.gca().add_patch(circle)\n",
    "        pyplot.gca().text(self.x, self.y-0.15, str(id), size=20, ha='center')\n",
    "\n",
    "class Layer():\n",
    "    def __init__(self, network, number_of_neurons, number_of_neurons_in_widest_layer):\n",
    "        self.vertical_distance_between_layers = 20\n",
    "        self.horizontal_distance_between_neurons = 6\n",
    "        self.neuron_radius = 2.8\n",
    "        self.number_of_neurons_in_widest_layer = number_of_neurons_in_widest_layer\n",
    "        self.previous_layer = self.__get_previous_layer(network)\n",
    "        self.y = self.__calculate_layer_y_position()\n",
    "        self.neurons = self.__intialise_neurons(number_of_neurons)\n",
    "\n",
    "    def __intialise_neurons(self, number_of_neurons):\n",
    "        neurons = []\n",
    "        x = self.__calculate_left_margin_so_layer_is_centered(number_of_neurons)\n",
    "        for iteration in range(number_of_neurons):\n",
    "            neuron = Neuron(x, self.y)\n",
    "            neurons.append(neuron)\n",
    "            x += self.horizontal_distance_between_neurons\n",
    "        return neurons\n",
    "\n",
    "    def __calculate_left_margin_so_layer_is_centered(self, number_of_neurons):\n",
    "        return self.horizontal_distance_between_neurons * (self.number_of_neurons_in_widest_layer - number_of_neurons) / 2\n",
    "\n",
    "    def __calculate_layer_y_position(self):\n",
    "        if self.previous_layer:\n",
    "            return self.previous_layer.y + self.vertical_distance_between_layers\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def __get_previous_layer(self, network):\n",
    "        if len(network.layers) > 0:\n",
    "            return network.layers[-1]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def __line_between_two_neurons(self, neuron1, neuron2, weight=0.4, textoverlaphandler=None):\n",
    "        angle = atan((neuron2.x - neuron1.x) / float(neuron2.y - neuron1.y))\n",
    "        x_adjustment = self.neuron_radius * sin(angle)\n",
    "        y_adjustment = self.neuron_radius * cos(angle)\n",
    "\n",
    "        # assign colors to lines depending on the sign of the weight\n",
    "        #color=Tableau_10.mpl_colors[0]\n",
    "        #if weight > 0: color=Tableau_10.mpl_colors[1]\n",
    "        color=Plasma_3.mpl_colors[0]\n",
    "        if weight > 0: color=Plasma_3.mpl_colors[1]\n",
    "\n",
    "        # assign different linewidths to lines depending on the size of the weight\n",
    "        abs_weight = abs(weight)        \n",
    "        if abs_weight > 0.5: \n",
    "            linewidth = 10*abs_weight\n",
    "        elif abs_weight > 0.8: \n",
    "            linewidth =  100*abs_weight\n",
    "        else:\n",
    "            linewidth = abs_weight\n",
    "\n",
    "        # draw the weights and adjust the labels of weights to avoid overlapping\n",
    "        if abs_weight > 0.5: \n",
    "            # while loop to determine the optimal locaton for text lables to avoid overlapping\n",
    "            index_step = 2\n",
    "            num_segments = 10   \n",
    "            txt_x_pos = neuron1.x - x_adjustment+index_step*(neuron2.x-neuron1.x+2*x_adjustment)/num_segments\n",
    "            txt_y_pos = neuron1.y - y_adjustment+index_step*(neuron2.y-neuron1.y+2*y_adjustment)/num_segments\n",
    "            while ((not textoverlaphandler.getspace([txt_x_pos-0.5, txt_y_pos-0.5, txt_x_pos+0.5, txt_y_pos+0.5])) and index_step < num_segments):\n",
    "                index_step = index_step + 1\n",
    "                txt_x_pos = neuron1.x - x_adjustment+index_step*(neuron2.x-neuron1.x+2*x_adjustment)/num_segments\n",
    "                txt_y_pos = neuron1.y - y_adjustment+index_step*(neuron2.y-neuron1.y+2*y_adjustment)/num_segments\n",
    "\n",
    "            # print(\"Label positions: \", \"{:.2f}\".format(txt_x_pos), \"{:.2f}\".format(txt_y_pos), \"{:3.2f}\".format(weight))\n",
    "            a=pyplot.gca().text(txt_x_pos, txt_y_pos, \"{:3.2f}\".format(weight), size=20, ha='center')\n",
    "            a.set_bbox(dict(facecolor='white', alpha=0.5))\n",
    "            # print(a.get_bbox_patch().get_height())\n",
    "\n",
    "        line = pyplot.Line2D((neuron1.x - x_adjustment, neuron2.x + x_adjustment), (neuron1.y - y_adjustment, neuron2.y + y_adjustment), linewidth=linewidth, color=color)\n",
    "        pyplot.gca().add_line(line)\n",
    "\n",
    "    def draw(self, layerType=0, weights=None, textoverlaphandler=None):\n",
    "        j=0 # index for neurons in this layer\n",
    "        feat=['0','Pro-MC', 'Carboxyl', 'Amide', 'His', 'Trp', 'Phe-Tyr', 'CH2','CH', 'CH3', 'OH', 'SH', 'S', 'NH3', \n",
    "              'Arg', 'MC'] #feature labels\n",
    "        for neuron in self.neurons:            \n",
    "            i=0 # index for neurons in previous layer\n",
    "            if layerType == 0:\n",
    "                neuron.draw(self.neuron_radius, id=feat[j+1])\n",
    "            else:\n",
    "                neuron.draw( self.neuron_radius, id=j+1 )\n",
    "            if self.previous_layer:\n",
    "                for previous_layer_neuron in self.previous_layer.neurons:\n",
    "                    self.__line_between_two_neurons(neuron, previous_layer_neuron, weights[i,j], textoverlaphandler)\n",
    "                    i=i+1\n",
    "            j=j+1\n",
    "        \n",
    "        # write Text\n",
    "        x_text = self.number_of_neurons_in_widest_layer * self.horizontal_distance_between_neurons\n",
    "        if layerType == 0:\n",
    "            pyplot.text(x_text, self.y, 'Input Layer', fontsize = 20)\n",
    "        elif layerType == -1:\n",
    "            pyplot.text(x_text, self.y, 'Output Layer', fontsize = 20)\n",
    "        else:\n",
    "            pyplot.text(x_text, self.y, 'Hidden Layer '+str(layerType), fontsize = 20)\n",
    "\n",
    "# A class to handle Text Overlapping\n",
    "# The idea is to first create a grid space, if a grid is already occupied, then\n",
    "# the grid is not available for text labels.\n",
    "class TextOverlappingHandler():\n",
    "    # initialize the class with the width and height of the plot area\n",
    "    def __init__(self, width, height, grid_size=0.2):\n",
    "        self.grid_size = grid_size\n",
    "        self.cells = np.ones((int(np.ceil(width / grid_size)), int(np.ceil(height / grid_size))), dtype=bool)\n",
    "\n",
    "    # input test_coordinates(bottom left and top right), \n",
    "    # getspace will tell you whether a text label can be put in the test coordinates\n",
    "    def getspace(self, test_coordinates):\n",
    "        x_left_pos = int(np.floor(test_coordinates[0]/self.grid_size))\n",
    "        y_botttom_pos = int(np.floor(test_coordinates[1]/self.grid_size))\n",
    "        x_right_pos = int(np.floor(test_coordinates[2]/self.grid_size))\n",
    "        y_top_pos = int(np.floor(test_coordinates[3]/self.grid_size))\n",
    "        if self.cells[x_left_pos, y_botttom_pos] and self.cells[x_left_pos, y_top_pos] \\\n",
    "        and self.cells[x_right_pos, y_top_pos] and self.cells[x_right_pos, y_botttom_pos]:\n",
    "            for i in range(x_left_pos, x_right_pos):\n",
    "                for j in range(y_botttom_pos, y_top_pos):\n",
    "                    self.cells[i, j] = False\n",
    "\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, number_of_neurons_in_widest_layer):\n",
    "        self.number_of_neurons_in_widest_layer = number_of_neurons_in_widest_layer\n",
    "        self.layers = []\n",
    "        self.layertype = 0\n",
    "\n",
    "    def add_layer(self, number_of_neurons ):\n",
    "        layer = Layer(self, number_of_neurons, self.number_of_neurons_in_widest_layer)\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def draw(self, weights_list=None):\n",
    "        # vertical_distance_between_layers and horizontal_distance_between_neurons are the same with the variables of the same name in layer class\n",
    "        vertical_distance_between_layers = 20\n",
    "        horizontal_distance_between_neurons = 6\n",
    "        overlaphandler = TextOverlappingHandler(\\\n",
    "            self.number_of_neurons_in_widest_layer*horizontal_distance_between_neurons,\\\n",
    "            len(self.layers)*vertical_distance_between_layers, grid_size=0.2 )\n",
    "\n",
    "        pyplot.figure(figsize=(30, 30))\n",
    "        for i in range( len(self.layers) ):\n",
    "            layer = self.layers[i]                                \n",
    "            if i == 0:\n",
    "                layer.draw( layerType=0 )\n",
    "            elif i == len(self.layers)-1:\n",
    "                layer.draw( layerType=-1, weights=weights_list[i-1], textoverlaphandler=overlaphandler)\n",
    "            else:\n",
    "                layer.draw( layerType=i, weights=weights_list[i-1], textoverlaphandler=overlaphandler)\n",
    "\n",
    "        pyplot.axis('scaled')\n",
    "        pyplot.axis('off')\n",
    "        #pyplot.title( 'Neural Network architecture', fontsize=15 )\n",
    "        figureName='ANN_'+strftime(\"%Y%m%d_%H%M%S\", localtime())+'.svg'\n",
    "        pyplot.savefig(figureName, dpi=300, bbox_inches=\"tight\")\n",
    "        pyplot.show()\n",
    "\n",
    "class DrawNN():\n",
    "    # para: neural_network is an array of the number of neurons \n",
    "    # from input layer to output layer, e.g., a neural network of 5 nerons in the input layer, \n",
    "    # 10 neurons in the hidden layer 1 and 1 neuron in the output layer is [5, 10, 1]\n",
    "    # para: weights_list (optional) is the output weights list of a neural network which can be obtained via classifier.coefs_\n",
    "    def __init__( self, neural_network, weights_list=None ):\n",
    "        self.neural_network = neural_network\n",
    "        self.weights_list = weights_list\n",
    "        # if weights_list is none, then create a uniform list to fill the weights_list\n",
    "        if weights_list is None:\n",
    "            weights_list=[]\n",
    "            for first, second in zip(neural_network, neural_network[1:]):\n",
    "                tempArr = np.ones((first, second))*0.4\n",
    "                weights_list.append(tempArr)\n",
    "            self.weights_list = weights_list\n",
    "        \n",
    "    def draw( self ):\n",
    "        widest_layer = max( self.neural_network )\n",
    "        network = NeuralNetwork( widest_layer )\n",
    "        for l in self.neural_network:\n",
    "            network.add_layer(l)\n",
    "        network.draw(self.weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80addcb5-9bc9-40b5-b7a9-60d533f8de5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier.fit(X, y.ravel())\n",
    "network_structure = np.hstack(([X_train.shape[1]], np.asarray(clf.hidden_layer_sizes), training_set_outputs.shape[1]))\n",
    "\n",
    "# Draw the Neural Network with weights\n",
    "network=DrawNN(network_structure, clf.coefs_)\n",
    "fig=network.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ad36ea-ca34-411e-9bb7-c5ccf575bfcb",
   "metadata": {},
   "source": [
    "## 7. [FIG S1, S2, S3] T-SNE FIGURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aebe32-0d0b-4cab-95b6-4dcf7d2c3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3362146e-011b-478b-bf16-9c0644db8fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, verbose=1, random_state=123)\n",
    "z = tsne.fit_transform(featx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d73498-2fb8-49e0-8b12-87c00c6bf144",
   "metadata": {},
   "outputs": [],
   "source": [
    "vf = pd.DataFrame()\n",
    "vf[\"y\"] = np.array(mergepf[u'Survivin, 1 µg/ml']!=0)\n",
    "vf[\"comp-1\"] = z[:,0]\n",
    "vf[\"comp-2\"] = z[:,1]\n",
    "vff=pd.concat([vf,transpf], axis=1, sort=False)\n",
    "vff['Uniprot ID']=pf['Uniprot ID']\n",
    "vff['Survivin, 1 µg/ml']=pf['Survivin, 1 µg/ml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e652484-903d-44c9-a997-b0fcdde77e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "#Use this to see binders vs non-binders\n",
    "fig = px.scatter(x=vff[\"comp-1\"], y=vff[\"comp-2\"],color=vff.y.tolist(), color_discrete_sequence=[\"cyan\", \"lightcoral\"])\n",
    "\n",
    "#Use this to see binding intensity\n",
    "#fig = px.scatter(vff, x=\"comp-1\", y=\"comp-2\",color=vff['Survivin, 1 µg/ml'].tolist(), \n",
    "#                 color_continuous_scale=px.colors.sequential.Inferno_r, hover_data=['Uniprot ID', 'Survivin, 1 µg/ml'])\n",
    "\n",
    "fig.update_traces(marker=dict(size=5,\n",
    "                              line=dict(width=0.5,\n",
    "                                        color='Snow')),\n",
    "                  selector=dict(mode='markers'))\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
